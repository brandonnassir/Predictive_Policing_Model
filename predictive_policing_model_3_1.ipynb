{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonnassir/Predictive_Policing_Model/blob/main/predictive_policing_model_3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c99245cf",
      "metadata": {
        "id": "c99245cf"
      },
      "outputs": [],
      "source": [
        "# Import the neccessary libraries\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import Image\n",
        "import geopandas as gpd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "#Change the current working directory to the path of Google Cloud Drive\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n",
        "#Use the wget command to download the dataset to this path\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/data.csv\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/combined_data.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up-A28myhU5o",
        "outputId": "b26c747d-a2b4-4a48-e079-66c36b484a12"
      },
      "id": "up-A28myhU5o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "--2024-06-17 13:50:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/data.csv\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.124, 108.157.254.15, 108.157.254.121, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2024-06-17 13:50:30 ERROR 403: Forbidden.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path)\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xq_a_ALh7RV",
        "outputId": "8c70d36d-49be-40ac-b7d7-4380206d44eb",
        "collapsed": true
      },
      "id": "_xq_a_ALh7RV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      DATE OCC  Hour of Day  Months  Days of Week         0         1  \\\n",
              "0   2020-01-01          0.0     1.0           4.0  0.000000  1.896940   \n",
              "1   2020-01-01          1.0     1.0           4.0  0.000000  0.686274   \n",
              "2   2020-01-01          2.0     1.0           4.0  0.000000  0.760256   \n",
              "3   2020-01-01          3.0     1.0           4.0  0.000000  0.837869   \n",
              "4   2020-01-01          4.0     1.0           4.0  0.000000  0.366070   \n",
              "5   2020-01-01          5.0     1.0           4.0  0.045271  0.736405   \n",
              "6   2020-01-01          6.0     1.0           4.0  0.000000  0.122619   \n",
              "7   2020-01-01          7.0     1.0           4.0  0.000000  0.620213   \n",
              "8   2020-01-01          8.0     1.0           4.0  0.000000  1.430662   \n",
              "9   2020-01-01          9.0     1.0           4.0  0.000000  1.168270   \n",
              "10  2020-01-01         10.0     1.0           4.0  0.000000  0.394417   \n",
              "11  2020-01-01         11.0     1.0           4.0  0.000000  0.714588   \n",
              "12  2020-01-01         12.0     1.0           4.0  0.000000  1.873134   \n",
              "13  2020-01-01         13.0     1.0           4.0  0.000000  0.343111   \n",
              "14  2020-01-01         14.0     1.0           4.0  0.000000  0.584847   \n",
              "15  2020-01-01         15.0     1.0           4.0  0.000000  0.693951   \n",
              "16  2020-01-01         16.0     1.0           4.0  0.039545  0.772395   \n",
              "17  2020-01-01         17.0     1.0           4.0  0.087214  0.823104   \n",
              "18  2020-01-01         18.0     1.0           4.0  0.000000  1.062942   \n",
              "19  2020-01-01         19.0     1.0           4.0  0.000000  0.445734   \n",
              "\n",
              "           2         3         4         5  ...        50        51        52  \\\n",
              "0   1.716223  0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.393447   \n",
              "1   0.041985  0.000000  0.000000  0.532548  ...  0.709240  0.198785  0.329118   \n",
              "2   0.000000  0.000000  0.151034  0.000000  ...  0.000000  0.089470  0.451233   \n",
              "3   0.497633  0.000000  0.000000  0.136928  ...  0.000000  0.099430  0.349515   \n",
              "4   0.395046  0.000000  0.000000  0.067603  ...  0.000000  0.373876  0.149449   \n",
              "5   0.000000  0.000000  0.114290  0.230526  ...  0.176646  0.170593  0.192686   \n",
              "6   0.188942  0.000000  0.000000  0.161990  ...  0.000000  0.272392  0.240340   \n",
              "7   0.408612  0.058511  0.107069  0.075612  ...  0.036446  0.000000  0.464607   \n",
              "8   0.573339  0.000000  0.027917  0.387142  ...  0.579125  0.000000  0.662120   \n",
              "9   0.631791  0.047208  0.000000  0.281198  ...  0.000000  0.140309  0.548994   \n",
              "10  0.000000  0.000000  0.000000  0.202199  ...  0.000000  0.423315  0.280933   \n",
              "11  0.029426  0.000000  0.000000  0.166211  ...  0.160770  0.234456  0.025535   \n",
              "12  1.052816  0.000000  0.000000  0.000000  ...  0.000000  0.814232  1.293977   \n",
              "13  0.351334  0.148036  0.000000  0.000000  ...  0.372599  0.234337  0.000000   \n",
              "14  0.334847  0.000000  0.234809  0.229576  ...  0.000000  0.492225  0.223025   \n",
              "15  0.201745  0.000000  0.000000  0.292796  ...  0.103975  0.425803  0.397106   \n",
              "16  0.033680  0.193690  0.388446  0.000000  ...  0.000000  0.127480  0.136204   \n",
              "17  0.399312  0.000000  0.004874  0.000000  ...  0.054501  0.032032  0.155522   \n",
              "18  0.065867  0.000000  0.000000  0.000000  ...  0.276282  0.474631  0.393710   \n",
              "19  0.385090  0.114523  0.000000  0.000000  ...  0.054782  0.041736  0.339689   \n",
              "\n",
              "          53        54        55        56        57        58        59  \n",
              "0   0.000000  0.362277  0.000000  0.160257  0.000000  0.333328  0.000000  \n",
              "1   0.000000  0.840384  0.000000  0.000000  0.000000  0.327572  0.281545  \n",
              "2   0.129547  0.096640  0.000000  0.000000  0.000000  0.317395  0.000000  \n",
              "3   0.304322  0.387116  0.000000  0.223926  0.041582  0.044034  0.028660  \n",
              "4   0.000000  0.792519  0.000000  0.182992  0.000000  0.000000  0.152160  \n",
              "5   0.017320  0.035072  0.000000  0.158550  0.000000  0.198398  0.000000  \n",
              "6   0.000000  0.560388  0.000000  0.176199  0.000000  0.073637  0.000000  \n",
              "7   0.274266  0.404927  0.000000  0.129521  0.004807  0.071081  0.000000  \n",
              "8   0.361142  0.274215  0.000000  0.229177  0.000000  0.000000  0.000000  \n",
              "9   0.000000  0.338665  0.000000  0.160728  0.224059  0.000000  0.140151  \n",
              "10  0.000000  0.639331  0.000000  0.174753  0.184258  0.333238  0.000000  \n",
              "11  0.000000  0.178736  0.000000  0.064080  0.268841  0.102259  0.200509  \n",
              "12  0.000000  0.941428  0.000000  0.000000  0.000000  0.799294  0.308520  \n",
              "13  0.000000  0.815726  0.210656  0.000000  0.018265  0.250926  0.055709  \n",
              "14  0.000000  0.311081  0.000000  0.130660  0.105595  0.149218  0.000000  \n",
              "15  0.000000  0.860881  0.000000  0.000000  0.000000  0.123431  0.242599  \n",
              "16  0.000000  0.030772  0.000000  0.087951  0.000000  0.416909  0.000000  \n",
              "17  0.000000  0.149389  0.041604  0.018227  0.000000  0.000000  0.084682  \n",
              "18  0.000000  0.599957  0.000000  0.000000  0.000000  0.143362  0.081114  \n",
              "19  0.054073  0.389063  0.000000  0.108491  0.000000  0.247386  0.000000  \n",
              "\n",
              "[20 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6d84905-cf93-4234-97d0-40d88901ea3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE OCC</th>\n",
              "      <th>Hour of Day</th>\n",
              "      <th>Months</th>\n",
              "      <th>Days of Week</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.896940</td>\n",
              "      <td>1.716223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.393447</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.362277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333328</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.686274</td>\n",
              "      <td>0.041985</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.532548</td>\n",
              "      <td>...</td>\n",
              "      <td>0.709240</td>\n",
              "      <td>0.198785</td>\n",
              "      <td>0.329118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.840384</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.327572</td>\n",
              "      <td>0.281545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.760256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089470</td>\n",
              "      <td>0.451233</td>\n",
              "      <td>0.129547</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.317395</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.837869</td>\n",
              "      <td>0.497633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136928</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099430</td>\n",
              "      <td>0.349515</td>\n",
              "      <td>0.304322</td>\n",
              "      <td>0.387116</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223926</td>\n",
              "      <td>0.041582</td>\n",
              "      <td>0.044034</td>\n",
              "      <td>0.028660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366070</td>\n",
              "      <td>0.395046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.373876</td>\n",
              "      <td>0.149449</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.792519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.182992</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.152160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.045271</td>\n",
              "      <td>0.736405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114290</td>\n",
              "      <td>0.230526</td>\n",
              "      <td>...</td>\n",
              "      <td>0.176646</td>\n",
              "      <td>0.170593</td>\n",
              "      <td>0.192686</td>\n",
              "      <td>0.017320</td>\n",
              "      <td>0.035072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.158550</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198398</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.122619</td>\n",
              "      <td>0.188942</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272392</td>\n",
              "      <td>0.240340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.560388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176199</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073637</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.620213</td>\n",
              "      <td>0.408612</td>\n",
              "      <td>0.058511</td>\n",
              "      <td>0.107069</td>\n",
              "      <td>0.075612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036446</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464607</td>\n",
              "      <td>0.274266</td>\n",
              "      <td>0.404927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129521</td>\n",
              "      <td>0.004807</td>\n",
              "      <td>0.071081</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.430662</td>\n",
              "      <td>0.573339</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027917</td>\n",
              "      <td>0.387142</td>\n",
              "      <td>...</td>\n",
              "      <td>0.579125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.662120</td>\n",
              "      <td>0.361142</td>\n",
              "      <td>0.274215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.229177</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.168270</td>\n",
              "      <td>0.631791</td>\n",
              "      <td>0.047208</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.281198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140309</td>\n",
              "      <td>0.548994</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338665</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160728</td>\n",
              "      <td>0.224059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.394417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202199</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.423315</td>\n",
              "      <td>0.280933</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.639331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174753</td>\n",
              "      <td>0.184258</td>\n",
              "      <td>0.333238</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714588</td>\n",
              "      <td>0.029426</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160770</td>\n",
              "      <td>0.234456</td>\n",
              "      <td>0.025535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064080</td>\n",
              "      <td>0.268841</td>\n",
              "      <td>0.102259</td>\n",
              "      <td>0.200509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.873134</td>\n",
              "      <td>1.052816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814232</td>\n",
              "      <td>1.293977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.941428</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799294</td>\n",
              "      <td>0.308520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343111</td>\n",
              "      <td>0.351334</td>\n",
              "      <td>0.148036</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.372599</td>\n",
              "      <td>0.234337</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.815726</td>\n",
              "      <td>0.210656</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.250926</td>\n",
              "      <td>0.055709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.584847</td>\n",
              "      <td>0.334847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234809</td>\n",
              "      <td>0.229576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.492225</td>\n",
              "      <td>0.223025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130660</td>\n",
              "      <td>0.105595</td>\n",
              "      <td>0.149218</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693951</td>\n",
              "      <td>0.201745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.103975</td>\n",
              "      <td>0.425803</td>\n",
              "      <td>0.397106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.860881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.123431</td>\n",
              "      <td>0.242599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.039545</td>\n",
              "      <td>0.772395</td>\n",
              "      <td>0.033680</td>\n",
              "      <td>0.193690</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.127480</td>\n",
              "      <td>0.136204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030772</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.416909</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.087214</td>\n",
              "      <td>0.823104</td>\n",
              "      <td>0.399312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004874</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054501</td>\n",
              "      <td>0.032032</td>\n",
              "      <td>0.155522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149389</td>\n",
              "      <td>0.041604</td>\n",
              "      <td>0.018227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062942</td>\n",
              "      <td>0.065867</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.276282</td>\n",
              "      <td>0.474631</td>\n",
              "      <td>0.393710</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.599957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143362</td>\n",
              "      <td>0.081114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445734</td>\n",
              "      <td>0.385090</td>\n",
              "      <td>0.114523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054782</td>\n",
              "      <td>0.041736</td>\n",
              "      <td>0.339689</td>\n",
              "      <td>0.054073</td>\n",
              "      <td>0.389063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.247386</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 64 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6d84905-cf93-4234-97d0-40d88901ea3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6d84905-cf93-4234-97d0-40d88901ea3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6d84905-cf93-4234-97d0-40d88901ea3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad4c779c-7932-4373-938e-777abb1c7c4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad4c779c-7932-4373-938e-777abb1c7c4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad4c779c-7932-4373-938e-777abb1c7c4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDbP2L2FjTWc",
        "outputId": "374b27f0-38c8-49bc-90fd-e9bf4e1de10c"
      },
      "id": "PDbP2L2FjTWc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35040, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your data\n",
        "data = df\n",
        "\n",
        "# 1. Encode Date Features\n",
        "\n",
        "# Convert DATE OCC to datetime\n",
        "data['DATE OCC'] = pd.to_datetime(data['DATE OCC'])\n",
        "\n",
        "# Extract day of the year\n",
        "data['DayOfYear'] = data['DATE OCC'].dt.dayofyear\n",
        "\n",
        "# Normalize day of the year\n",
        "data['DayOfYear'] = data['DayOfYear'] / 365.0\n",
        "\n",
        "# Sine and cosine transformations for cyclical features\n",
        "data['HourOfDay_sin'] = np.sin(2 * np.pi * data['Hour of Day'] / 24)\n",
        "data['HourOfDay_cos'] = np.cos(2 * np.pi * data['Hour of Day'] / 24)\n",
        "data['Month_sin'] = np.sin(2 * np.pi * data['Months'] / 12)\n",
        "data['Month_cos'] = np.cos(2 * np.pi * data['Months'] / 12)\n",
        "data['DayOfWeek_sin'] = np.sin(2 * np.pi * data['Days of Week'] / 7)\n",
        "data['DayOfWeek_cos'] = np.cos(2 * np.pi * data['Days of Week'] / 7)\n",
        "\n",
        "# Drop the original columns\n",
        "data.drop(columns=['DATE OCC', 'Hour of Day', 'Months', 'Days of Week'], inplace=True)\n",
        "\n",
        "# 2. Scale the Data\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# 3. Prepare Sequences for LSTM\n",
        "\n",
        "def create_sequences(data, time_steps=10):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        seq = data[i:i + time_steps]\n",
        "        sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "time_steps = 24 # You can change this based on your problem\n",
        "sequences = create_sequences(scaled_data, time_steps)\n",
        "\n",
        "# Now, split the sequences into input (X) and output (y)\n",
        "X = sequences[:, :-1, :]\n",
        "y = sequences[:, -1, :60] # Assuming columns 0 - 59 are the targets\n",
        "\n",
        "# 4. Split the Data into Training and Test Sets\n",
        "\n",
        "# Define the point where you want to split the data (e.g., 80% for training)\n",
        "split_point = int(len(X) * 0.8)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test = X[:split_point], X[split_point:]\n",
        "y_train, y_test = y[:split_point], y[split_point:]\n",
        "\n",
        "\n",
        "# Check the shapes of the resulting datasets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxsH3sSvqARf",
        "outputId": "08d0068a-b6fb-4958-a454-2ec9b918dcd1"
      },
      "id": "AxsH3sSvqARf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (28012, 23, 67)\n",
            "X_test shape: (7004, 23, 67)\n",
            "y_train shape: (28012, 60)\n",
            "y_test shape: (7004, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the number of features\n",
        "n_features = X_train.shape[2]\n",
        "sequence_length = X_train.shape[1]\n",
        "\n",
        "learning_rate = 0.00001\n",
        "batch_size = 64  # Change this as neede\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    # LSTM layer with 50 units\n",
        "    LSTM(50, return_sequences=False, input_shape=(sequence_length, n_features)),\n",
        "\n",
        "    # Dense layer with 64 units and ReLU activation\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    # Dense layer with 128 units and ReLU activation\n",
        "    Dense(128, activation='linear'),\n",
        "\n",
        "    # Dense layer with 256 units and linear activation\n",
        "    Dense(256, activation='sigmoid'),\n",
        "\n",
        "    # Output layer with the number of units equal to the target variables and sigmoid activation\n",
        "    Dense(units=y_train.shape[1], activation='relu')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbeJQa59u93z",
        "outputId": "c21ecacb-bb02-4067-f366-f5e9e928d66d"
      },
      "id": "wbeJQa59u93z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50)                23600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                3264      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 60)                15420     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83628 (326.67 KB)\n",
            "Trainable params: 83628 (326.67 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.00001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "nMbTp0Rkgc1Q"
      },
      "id": "nMbTp0Rkgc1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=4800, batch_size=1028)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hlNW373vvmzz",
        "outputId": "1f9bfae8-aeb2-4e25-b503-e33388845490"
      },
      "id": "hlNW373vvmzz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4800\n",
            "28/28 [==============================] - 4s 6ms/step - loss: 0.0575\n",
            "Epoch 2/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0498\n",
            "Epoch 3/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0434\n",
            "Epoch 4/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0381\n",
            "Epoch 5/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0335\n",
            "Epoch 6/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0296\n",
            "Epoch 7/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0262\n",
            "Epoch 8/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0234\n",
            "Epoch 9/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0209\n",
            "Epoch 10/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0188\n",
            "Epoch 11/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0171\n",
            "Epoch 12/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0157\n",
            "Epoch 13/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0146\n",
            "Epoch 14/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0137\n",
            "Epoch 15/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131\n",
            "Epoch 16/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0126\n",
            "Epoch 17/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0123\n",
            "Epoch 18/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0121\n",
            "Epoch 19/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0120\n",
            "Epoch 20/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0119\n",
            "Epoch 21/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0119\n",
            "Epoch 22/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0119\n",
            "Epoch 23/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0119\n",
            "Epoch 24/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 25/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 26/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 27/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 28/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 29/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 30/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 31/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 32/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 33/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 34/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 35/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 36/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 37/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 38/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 39/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 40/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 41/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 42/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 43/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 44/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 45/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 46/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 47/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 48/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 49/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 50/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 51/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 52/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 53/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 54/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 55/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 56/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 57/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 58/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 59/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 60/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 61/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 62/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 63/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 64/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 65/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 66/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 67/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 68/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 69/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 70/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 71/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 72/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 73/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 74/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 75/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 76/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 77/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 78/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 79/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 80/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 81/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 82/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 83/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 84/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 85/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 86/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 87/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 88/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 89/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 90/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 91/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 92/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 93/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 94/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 95/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 96/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 97/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 98/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 99/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 100/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 101/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 102/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 103/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 104/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 105/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 106/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 107/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 108/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 109/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 110/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 111/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 112/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 113/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 114/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 115/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 116/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
            "Epoch 117/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 118/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 119/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 120/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 121/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 122/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 123/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 124/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 125/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 126/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 127/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 128/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 129/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 130/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 131/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 132/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 133/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 134/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 135/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 136/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 137/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 138/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 139/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 140/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 141/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 142/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 143/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 144/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 145/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 146/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 147/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 148/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 149/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 150/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 151/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 152/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 153/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 154/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 155/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 156/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 157/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 158/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 159/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 160/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 161/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 162/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 163/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 164/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 165/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 166/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 167/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 168/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 169/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 170/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 171/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 172/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 173/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 174/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 175/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 176/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 177/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 178/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 179/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 180/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 181/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 182/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 183/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 184/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 185/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 186/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 187/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 188/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 189/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 190/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 191/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 192/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 193/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 194/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 195/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 196/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 197/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 198/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 199/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 200/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 201/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 202/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 203/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 204/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 205/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 206/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 207/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 208/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 209/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 210/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 211/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 212/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 213/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 214/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 215/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 216/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 217/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 218/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 219/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 220/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 221/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 222/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 223/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 224/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 225/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 226/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 227/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 228/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 229/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 230/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 231/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 232/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 233/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 234/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 235/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 236/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 237/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 238/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 239/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 240/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 241/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 242/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 243/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 244/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 245/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 246/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 247/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 248/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 249/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 250/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 251/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 252/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 253/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 254/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 255/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 256/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 257/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 258/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 259/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 260/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 261/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 262/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 263/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 264/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 265/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 266/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 267/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 268/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 269/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 270/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 271/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 272/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 273/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 274/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 275/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 276/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 277/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 278/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 279/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 280/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 281/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 282/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 283/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 284/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 285/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 286/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 287/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 288/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 289/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 290/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 291/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 292/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 293/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 294/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 295/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 296/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 297/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 298/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 299/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 300/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 301/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 302/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 303/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 304/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 305/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 306/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 307/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 308/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 309/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 310/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 311/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 312/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 313/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 314/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 315/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 316/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 317/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 318/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 319/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 320/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 321/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 322/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 323/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 324/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 325/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 326/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 327/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 328/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 329/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 330/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 331/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 332/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 333/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 334/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 335/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 336/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 337/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 338/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 339/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 340/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 341/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 342/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 343/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 344/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 345/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 346/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 347/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 348/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 349/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 350/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 351/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 352/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 353/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 354/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 355/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 356/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 357/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 358/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 359/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 360/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 361/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 362/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 363/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 364/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 365/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 366/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 367/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 368/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 369/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 370/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 371/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 372/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 373/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 374/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 375/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 376/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 377/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 378/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 379/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 380/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 381/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 382/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 383/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 384/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 385/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 386/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 387/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 388/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 389/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 390/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 391/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 392/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 393/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 394/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 395/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 396/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 397/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 398/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 399/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 400/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 401/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 402/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 403/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 404/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 405/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 406/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 407/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 408/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 409/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 410/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 411/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 412/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 413/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 414/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 415/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 416/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 417/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 418/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 419/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 420/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 421/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 422/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 423/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 424/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 425/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 426/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 427/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 428/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 429/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 430/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 431/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 432/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 433/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 434/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 435/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 436/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 437/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 438/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 439/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 440/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 441/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 442/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 443/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 444/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 445/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 446/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 447/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 448/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 449/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 450/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 451/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 452/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 453/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 454/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 455/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 456/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 457/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 458/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 459/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 460/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 461/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 462/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 463/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 464/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 465/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 466/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 467/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 468/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 469/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 470/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 471/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 472/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 473/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 474/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 475/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 476/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 477/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 478/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 479/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 480/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 481/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 482/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 483/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 484/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 485/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 486/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 487/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 488/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 489/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 490/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 491/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 492/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 493/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 494/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 495/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 496/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 497/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 498/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 499/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 500/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 501/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 502/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 503/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 504/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 505/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 506/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 507/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 508/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 509/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 510/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 511/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 512/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 513/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 514/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 515/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 516/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 517/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 518/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 519/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 520/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 521/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 522/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 523/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 524/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 525/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 526/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 527/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 528/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 529/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 530/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 531/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 532/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 533/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 534/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 535/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 536/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 537/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 538/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 539/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 540/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 541/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 542/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 543/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 544/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 545/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 546/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 547/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 548/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 549/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 550/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 551/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 552/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 553/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 554/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 555/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 556/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 557/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 558/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 559/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 560/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 561/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 562/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 563/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 564/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 565/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 566/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 567/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 568/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 569/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 570/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 571/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 572/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 573/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 574/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 575/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 576/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 577/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 578/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 579/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 580/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 581/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 582/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 583/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 584/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 585/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 586/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 587/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 588/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 589/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 590/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 591/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 592/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 593/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 594/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 595/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 596/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 597/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 598/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 599/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 600/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 601/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 602/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 603/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 604/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 605/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 606/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 607/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 608/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 609/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 610/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 611/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 612/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 613/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 614/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 615/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 616/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 617/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 618/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 619/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 620/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 621/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 622/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 623/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 624/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 625/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 626/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 627/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 628/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 629/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 630/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 631/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 632/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 633/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 634/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 635/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 636/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 637/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 638/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 639/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 640/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 641/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 642/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 643/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 644/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 645/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 646/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 647/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 648/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 649/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 650/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 651/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 652/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 653/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 654/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 655/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 656/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 657/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 658/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 659/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 660/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 661/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 662/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 663/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 664/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 665/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 666/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 667/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 668/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 669/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 670/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 671/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 672/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 673/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 674/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 675/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 676/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 677/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 678/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 679/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 680/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 681/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 682/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 683/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 684/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 685/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 686/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 687/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 688/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 689/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 690/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 691/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 692/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 693/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 694/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 695/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 696/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 697/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 698/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 699/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 700/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 701/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 702/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 703/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 704/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 705/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 706/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 707/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 708/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 709/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 710/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 711/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 712/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 713/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 714/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 715/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 716/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 717/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 718/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 719/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 720/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 721/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 722/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 723/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 724/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 725/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 726/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 727/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 728/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 729/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 730/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 731/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 732/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 733/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 734/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 735/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 736/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 737/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 738/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 739/4800\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0116\n",
            "Epoch 740/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 741/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 742/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 743/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 744/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 745/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 746/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 747/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 748/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 749/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 750/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 751/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 752/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 753/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 754/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 755/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 756/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 757/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 758/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 759/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 760/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 761/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 762/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 763/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 764/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 765/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 766/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 767/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 768/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 769/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 770/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 771/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 772/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 773/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 774/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 775/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 776/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 777/4800\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 778/4800\n",
            " 1/28 [>.............................] - ETA: 0s - loss: 0.0112"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d17c3d7aa250>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('model_3.keras')"
      ],
      "metadata": {
        "id": "bdT9oOJWWK0M"
      },
      "id": "bdT9oOJWWK0M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Path to your model\n",
        "#model_path_1 = '/content/drive/My Drive/Colab Notebooks/model_3_1.keras'\n",
        "model_path_2 = '/content/drive/My Drive/Colab Notebooks/autoencoder_model.keras'\n",
        "\n",
        "# Load the saved model\n",
        "#model_3_1 = load_model(model_path_1)\n",
        "model_3_1 = model\n",
        "autoencoder_model = load_model(model_path_2)"
      ],
      "metadata": {
        "id": "8qKUxBZyMrmj"
      },
      "id": "8qKUxBZyMrmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Define the encoder model structure\n",
        "#input_dim = data_x.shape[1]\n",
        "input_dim = 282\n",
        "encoding_dim = autoencoder_model.layers[2].output_shape[1]  # Assuming the encoding layer is the second Dense layer\n",
        "\n",
        "# Input for the decoder\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "\n",
        "# Recreate the decoder layers\n",
        "decoder_layer1 = autoencoder_model.layers[-3]\n",
        "decoder_layer2 = autoencoder_model.layers[-2]\n",
        "decoder_output_layer = autoencoder_model.layers[-1]\n",
        "\n",
        "# Build the decoder model\n",
        "decoder = Model(encoded_input, decoder_output_layer(decoder_layer2(decoder_layer1(encoded_input))))\n"
      ],
      "metadata": {
        "id": "wMEL9mvzYsZJ"
      },
      "id": "wMEL9mvzYsZJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data.iloc[:, :60])  # Scale only the first 60 columns"
      ],
      "metadata": {
        "id": "9jYM8eIKo9k1"
      },
      "id": "9jYM8eIKo9k1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaled_data, scaler):\n",
        "    return scaler.inverse_transform(scaled_data)\n",
        "\n",
        "# Example: transform LSTM predictions (embeddings) with the decoder\n",
        "embeddings = model_3_1.predict(X_test)  # Assume this gives you the embeddings\n",
        "\n",
        "\n",
        "# Inverse transform the embeddings\n",
        "embeddings_inverse = inverse_transform(embeddings, scaler)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vapjunk1ip6N",
        "outputId": "4e059540-3e78-42f9-e198-e67aa9c273bc"
      },
      "id": "Vapjunk1ip6N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the decoder to transform embeddings back to the original space\n",
        "decoded_predictions = decoder.predict(embeddings_inverse)\n",
        "\n",
        "# Now, you can evaluate the performance or use the decoded predictions as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Y1FUAQaJpX",
        "outputId": "a39bafb7-8fe8-4836-9f76-4f06e8b7c4a9"
      },
      "id": "d4Y1FUAQaJpX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_y_test = decoder.predict(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w-OkbkwCu-iW",
        "outputId": "63a74503-9c95-42bc-f6f6-6b216b55dab4"
      },
      "id": "w-OkbkwCu-iW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_predictions = (decoded_predictions > 0.5).astype(int)\n",
        "decoded_y_test = (decoded_y_test > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "2AfsxTsq1Jzc"
      },
      "id": "2AfsxTsq1Jzc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is your original training data and 'autoencoder' is your train\n",
        "\n",
        "# Count correct predictions\n",
        "correct_predictions = np.sum(decoded_predictions == decoded_y_test)\n",
        "\n",
        "print(f\"Number of correct element-wise predictions: {correct_predictions}\")\n",
        "print(f\"Number of total elements: {int(decoded_predictions.shape[0]*int(decoded_predictions.shape[1]))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kECxw2G815my",
        "outputId": "cd68f9cc-3fc6-41d8-8a1c-dfd8c0559ec0"
      },
      "id": "kECxw2G815my",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of correct element-wise predictions: 1908941\n",
            "Number of total elements: 1975128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "right = 0\n",
        "wrong = 0\n",
        "one_count_y = 0\n",
        "one_count_p = 0\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "for j in range(len(decoded_predictions)):\n",
        "    for i in range(len(decoded_predictions[j])):\n",
        "        if decoded_y_test[j][i] == decoded_predictions[j][i]:\n",
        "            right = right + 1\n",
        "        else:\n",
        "            wrong = wrong + 1\n",
        "\n",
        "        if decoded_y_test[j][i] == 1:\n",
        "            one_count_y = one_count_y + 1\n",
        "\n",
        "        if decoded_predictions[j][i] == 1:\n",
        "            one_count_p = one_count_p + 1\n",
        "\n",
        "        if (decoded_predictions[j][i] == decoded_y_test[j][i]) and (decoded_y_test[j][i] == 1):\n",
        "            true_positive = true_positive + 1\n",
        "\n",
        "        if (decoded_predictions[j][i] == 1) and (decoded_y_test[j][i] == 0):\n",
        "            false_positive = false_positive + 1\n",
        "\n",
        "        if (decoded_predictions[j][i] == 0) and (decoded_y_test[j][i] == 1):\n",
        "            false_negative = false_negative + 1\n",
        "\n",
        "precision = true_positive/(true_positive+false_positive)\n",
        "recall = true_positive/(true_positive + false_negative)\n",
        "f1_score = 2*(precision*recall)/(precision+recall)"
      ],
      "metadata": {
        "id": "JrLsfSsK2kFk"
      },
      "id": "JrLsfSsK2kFk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAccuracy:\", round(right/(right+wrong),2))\n",
        "print(\"\\nPrecisions\", round(true_positive/(true_positive+false_positive),2))\n",
        "print(\"\\nRecall:\", round(true_positive/(true_positive + false_negative),2))\n",
        "print(\"\\nF1 Score,\", round(f1_score,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN80b0Wz3M5y",
        "outputId": "63d3a6bb-626d-4bbe-e990-b0f18bfc982f"
      },
      "id": "HN80b0Wz3M5y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.97\n",
            "\n",
            "Precisions 0.92\n",
            "\n",
            "Recall: 0.95\n",
            "\n",
            "F1 Score, 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of times model predicted crime event outcome correctly:\",right)\n",
        "print(\"\\nTotal number of times model predicted crime event outcome incorrectly:\",wrong)\n",
        "print(\"\\nTotal number of times model predicted crime would occur in Test Set:\",one_count_p)\n",
        "print(\"\\nTotal number of times crime actually occured in Test Set:\",one_count_y)\n",
        "print(\"\\nNumber of times model predicted crime occuring and crime did occur:\",true_positive)\n",
        "print(\"\\nNumber of times model predicted crime occuring and crime did NOT occur:\", false_positive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0-gTHy63kJE",
        "outputId": "80efc73e-4e2f-45f9-a636-2c19955aac6e"
      },
      "id": "n0-gTHy63kJE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of times model predicted crime event outcome correctly: 1908941\n",
            "\n",
            "Total number of times model predicted crime event outcome incorrectly: 66187\n",
            "\n",
            "Total number of times model predicted crime would occur in Test Set: 522069\n",
            "\n",
            "Total number of times crime actually occured in Test Set: 509038\n",
            "\n",
            "Number of times model predicted crime occuring and crime did occur: 482460\n",
            "\n",
            "Number of times model predicted crime occuring and crime did NOT occur: 39609\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}